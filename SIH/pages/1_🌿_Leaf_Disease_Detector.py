import streamlit as st
from PIL import Image
import requests
import io
import base64
from sih.sih.config import HUGGINGFACE_API_KEY, MODEL_ID, API_URL, TIMEOUT_SECONDS, IMAGE_SIZE, IMAGE_QUALITY, MAX_FILE_SIZE_MB
from chatbot_component import AgriculturalChatbot

st.title("üåø Crop Leaf Disease Detector / ‡¥á‡¥≤ ‡¥∞‡µã‡¥ó ‡¥ï‡¥£‡µç‡¥ü‡µÜ‡¥§‡µç‡¥§‡µΩ")

def validate_api_token(api_token):
    if not api_token:
        return False, "No API token provided"
    if not api_token.startswith('hf_'):
        return False, "API token should start with 'hf_'"
    if len(api_token) < 20:
        return False, "API token appears to be too short"
    return True, "Valid token format"

def test_model_availability(api_token):
    headers = {"Authorization": f"Bearer {api_token}"}
    try:
        response = requests.get(f"https://api-inference.huggingface.co/models/{MODEL_ID}", headers=headers, timeout=TIMEOUT_SECONDS)
        if response.status_code == 200:
            return True, "Model is available"
        else:
            return False, f"Model check failed: {response.status_code}"
    except Exception as e:
        return False, f"Could not check model: {e}"

def query_api(image_bytes, api_token):
    is_valid, message = validate_api_token(api_token)
    if not is_valid:
        st.error(f"Invalid API token: {message}")
        st.info("üí° How to get your API token:")
        st.markdown("""
        1. Go to https://huggingface.co/settings/tokens
        2. Create a token with Read permissions
        3. Copy the token (starts with 'hf_')
        """)
        return None

    try:
        img_base64 = base64.b64encode(image_bytes).decode('utf-8')
    except Exception as e:
        st.error(f"Failed to encode image: {e}")
        return None

    headers = {"Authorization": f"Bearer {api_token}", "Content-Type": "application/json"}
    payload = {"inputs": img_base64}

    try:
        response = requests.post(API_URL, headers=headers, json=payload, timeout=TIMEOUT_SECONDS)
        if response.status_code == 400:
            st.error("Bad Request (400)")
            headers_alt = {"Authorization": f"Bearer {api_token}"}
            response_alt = requests.post(API_URL, headers=headers_alt, data=image_bytes, timeout=TIMEOUT_SECONDS)
            if response_alt.status_code == 200:
                return response_alt.json()
            return None
        elif response.status_code in (401, 403, 429, 503):
            st.error(f"API Error: {response.status_code}")
            return None
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        st.error(f"API request failed: {e}")
        return None

def format_prediction(prediction):
    if not prediction:
        return "No prediction available."
    top_result = sorted(prediction, key=lambda x: x['score'], reverse=True)[0]
    label = top_result['label'].replace("_", " ").title()
    score = top_result['score']
    return f"**{label}** (Confidence: {score:.2%})"

api_token = HUGGINGFACE_API_KEY

uploaded_file = st.file_uploader("Choose a leaf image... / ‡¥í‡¥∞‡µÅ ‡¥á‡¥≤ ‡¥ö‡¥ø‡¥§‡µç‡¥∞‡¥Ç ‡¥§‡¥ø‡¥∞‡¥û‡µç‡¥û‡µÜ‡¥ü‡µÅ‡¥ï‡µç‡¥ï‡µÅ‡¥ï...", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    try:
        image = Image.open(uploaded_file)
        if image.mode != 'RGB':
            image = image.convert('RGB')
        original_size = image.size
        image = image.resize(IMAGE_SIZE, Image.Resampling.LANCZOS)
        st.image(image, caption=f"Uploaded Leaf Image (resized to {IMAGE_SIZE[0]}x{IMAGE_SIZE[1]}) / ‡¥Ö‡¥™‡µç‚Äå‡¥≤‡µã‡¥°‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥§ ‡¥á‡¥≤ ‡¥ö‡¥ø‡¥§‡µç‡¥∞‡¥Ç ({IMAGE_SIZE[0]}x{IMAGE_SIZE[1]} ‡¥Ü‡¥Ø‡¥ø ‡¥µ‡¥≤‡µÅ‡¥™‡µç‡¥™‡¥Ç ‡¥Æ‡¥æ‡¥±‡µç‡¥±‡¥ø)", use_column_width=True)
        st.info(f"Original Size: {original_size[0]}x{original_size[1]} pixels / ‡¥Ø‡¥•‡¥æ‡µº‡¥§‡µç‡¥• ‡¥µ‡¥≤‡µÅ‡¥™‡µç‡¥™‡¥Ç: {original_size[0]}x{original_size[1]} ‡¥™‡¥ø‡¥ï‡µç‡¥∏‡µΩ")
        st.info(f"Processed Size: {image.size[0]}x{image.size[1]} pixels, Mode: {image.mode} / ‡¥™‡µç‡¥∞‡µã‡¥∏‡¥∏‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥§ ‡¥µ‡¥≤‡µÅ‡¥™‡µç‡¥™‡¥Ç: {image.size[0]}x{image.size[1]} ‡¥™‡¥ø‡¥ï‡µç‡¥∏‡µΩ, ‡¥Æ‡µã‡¥°‡µç: {image.mode}")
        img_byte_arr = io.BytesIO()
        image.save(img_byte_arr, format='JPEG', quality=IMAGE_QUALITY)
        img_bytes = img_byte_arr.getvalue()
        file_size_mb = len(img_bytes) / (1024 * 1024)
        st.info(f"File Size: {file_size_mb:.2f} MB / ‡¥´‡¥Ø‡µΩ ‡¥µ‡¥≤‡µÅ‡¥™‡µç‡¥™‡¥Ç: {file_size_mb:.2f} MB")
        if file_size_mb > MAX_FILE_SIZE_MB:
            st.warning("File is large. Consider using a smaller image. / ‡¥´‡¥Ø‡µΩ ‡¥µ‡¥≤‡µÅ‡¥§‡¥æ‡¥£‡µç. ‡¥ö‡µÜ‡¥±‡¥ø‡¥Ø ‡¥ö‡¥ø‡¥§‡µç‡¥∞‡¥Ç ‡¥â‡¥™‡¥Ø‡µã‡¥ó‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥ï.")
        if st.button("Classify Leaf / ‡¥á‡¥≤ ‡¥µ‡µº‡¥ó‡µÄ‡¥ï‡¥∞‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥ï", type="primary"):
            with st.spinner("Analyzing the image... / ‡¥ö‡¥ø‡¥§‡µç‡¥∞‡¥Ç ‡¥µ‡¥ø‡¥∂‡¥ï‡¥≤‡¥®‡¥Ç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥®‡µç‡¥®‡µÅ..."):
                prediction = query_api(img_bytes, api_token)
            st.subheader("Prediction Result: / ‡¥™‡µç‡¥∞‡¥µ‡¥ö‡¥® ‡¥´‡¥≤‡¥Ç:")
            if prediction:
                result_text = format_prediction(prediction)
                st.success(result_text)
                
                # Extract disease name for treatment advice
                top_result = sorted(prediction, key=lambda x: x['score'], reverse=True)[0]
                disease_name = top_result['label'].replace("_", " ").title()
                
                # Get treatment advice from chatbot
                st.markdown("---")
                st.subheader("Treatment Advice / ‡¥ö‡¥ø‡¥ï‡¥ø‡¥§‡µç‡¥∏‡¥æ ‡¥â‡¥™‡¥¶‡µá‡¥∂‡¥Ç")
                
                if 'chatbot' not in st.session_state:
                    st.session_state.chatbot = AgriculturalChatbot()
                
                chatbot = st.session_state.chatbot
                if chatbot.is_configured():
                    with st.spinner("Getting treatment advice... / ‡¥ö‡¥ø‡¥ï‡¥ø‡¥§‡µç‡¥∏‡¥æ ‡¥â‡¥™‡¥¶‡µá‡¥∂‡¥Ç ‡¥®‡µá‡¥ü‡µÅ‡¥®‡µç‡¥®‡µÅ..."):
                        treatment_query = f"{disease_name} ‡¥∞‡µã‡¥ó‡¥§‡µç‡¥§‡¥ø‡¥®‡µÅ‡¥≥‡µç‡¥≥ ‡¥ö‡¥ø‡¥ï‡¥ø‡¥§‡µç‡¥∏ ‡¥é‡¥®‡µç‡¥§‡¥æ‡¥£‡µç? ‡¥ú‡µà‡¥µ‡¥µ‡µÅ‡¥Ç ‡¥∞‡¥æ‡¥∏‡¥µ‡µÅ‡¥Æ‡¥æ‡¥Ø ‡¥ì‡¥™‡µç‡¥∑‡¥®‡µÅ‡¥ï‡µæ ‡¥â‡µæ‡¥™‡µç‡¥™‡µÜ‡¥ü‡µÜ ‡¥ö‡µÅ‡¥∞‡µÅ‡¥ï‡µç‡¥ï‡¥Æ‡¥æ‡¥Ø ‡¥ö‡¥ø‡¥ï‡¥ø‡¥§‡µç‡¥∏‡¥æ ‡¥®‡¥ø‡µº‡¥¶‡µç‡¥¶‡µá‡¥∂‡¥ô‡µç‡¥ô‡µæ ‡¥®‡µΩ‡¥ï‡µÅ‡¥ï."
                        treatment_advice = chatbot.process_text_query(treatment_query)
                        st.markdown(treatment_advice)
                else:
                    st.warning("Chatbot not configured. Please set GEMINI_API_KEY environment variable.")
                
                # Add report button
                st.markdown("---")
                if st.button("üìã Get Full Report", type="secondary"):
                    st.info("Full report feature coming soon!")
            else:
                st.error("Could not get a prediction. / ‡¥™‡µç‡¥∞‡¥µ‡¥ö‡¥®‡¥Ç ‡¥®‡µá‡¥ü‡¥æ‡µª ‡¥ï‡¥¥‡¥ø‡¥û‡µç‡¥û‡¥ø‡¥≤‡µç‡¥≤.")
    except Exception as e:
        st.error(f"Error processing image: {e} / ‡¥ö‡¥ø‡¥§‡µç‡¥∞‡¥Ç ‡¥™‡µç‡¥∞‡µã‡¥∏‡¥∏‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥Æ‡µç‡¥™‡µã‡µæ ‡¥™‡¥ø‡¥∂‡¥ï‡µç: {e}")
else:
    st.info("Please upload an image to get started. / ‡¥Ü‡¥∞‡¥Ç‡¥≠‡¥ø‡¥ï‡µç‡¥ï‡¥æ‡µª ‡¥í‡¥∞‡µÅ ‡¥ö‡¥ø‡¥§‡µç‡¥∞‡¥Ç ‡¥Ö‡¥™‡µç‚Äå‡¥≤‡µã‡¥°‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥ï.")



